{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461c897d-2e2d-4270-b557-ad81e1e28ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53692f2f-3720-4d63-aa6d-3339779761db",
   "metadata": {},
   "source": [
    "The Fashion MNIST dataset is a collection of grayscale 28x28 pixel clothing images. Each image is associated with a label as shown in this table‚Åâ\n",
    "|Label|Description|\n",
    "|---|---|\n",
    "|0|T-shirt/top|\n",
    "|1|Trouser|\n",
    "|2|Pullover|\n",
    "|3|Dress|\n",
    "|4|Coat|\n",
    "|5|Sandal|\n",
    "|6|Shirt|\n",
    "|7|Sneaker|\n",
    "|8|Bag|\n",
    "|9|Ankle boot|\n",
    "\n",
    "This dataset is available directly in the `tf.keras.datasets` API and you load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "136280e0-5c27-455a-855b-f69bb9445833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82501aaa-b35a-4e4e-b5e3-bce729523966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9c222f1-c8fa-4a46-9e89-f634cd97b057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  25 128 123 105  72   5   0   1   4   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   2   0 114 155 147 154 172 142   0   0   0   0   2  44 144 165   0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4   0 110 147 148 160 157 200   5   0  80 149 167 185 177 133   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0 123 145 142 175 154 207  11 116 239 186 184 178 166 141   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   0 141 140 122 151 136 203  31 181 180 179 179 175 172 182   3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0 135 145 141 154 155 210  66 179 186 185 171 166 157 214  48   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   1 127 151 155 164 160 210  76 180 178 165 165 170 154 167 140   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0  21 148 147 153 161 162 193 101 178 184 167 168 168 164 162 190   4]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0  49 162 149 160 168 175 185 184 195 182 177 168 170 161 160 200  46]\n",
      " [  0   0   0   0   1   0   2   1   2   0   0 128 170 159 166 177 187 179 180 188 168 165 157 162 171 168 194  51]\n",
      " [  0   0   0   0   0   2   0   0   3   0  54 166 151 165 166 173 179 179 170 178 180 174 174 177 180 179 205  48]\n",
      " [  0   0   0   0   1   0   0   5   0   4 128 139 154 162 165 172 175 174 177 185 181 186 185 186 182 182 198   4]\n",
      " [  1   0   0   0   0   0   5   0   0  99 145 128 144 149 158 170 178 179 178 191 181 171 166 175 172 168 106   0]\n",
      " [  0   2   3   3   2   4   0   0  90 131 113 133 151 159 153 171 181 182 181 177 206 218 201 190 165 162  34   0]\n",
      " [  4   0   0   0   0   0   7  81 131 119 132 142 159 166 164 179 180 186 171 220 152  15   0 144 178 159   0   0]\n",
      " [  0   0  31  48  68 100 120 119 123 138 144 147 158 154 168 177 180 172 216  99   0   0   0 115 201 125   0   0]\n",
      " [  9 122 139 121 133 120 115 129 132 141 151 155 160 170 182 181 171 221  70   0   0   5   0 115 208  59   0   1]\n",
      " [ 63 142 119 116 123 120 120 127 141 149 161 167 174 184 179 166 229  76   0   0   3   3   0 113 200   7   0   3]\n",
      " [ 54 175 147 139 129 133 142 138 145 154 166 164 170 181 164 220  79   0   0   1   0   0   0 126 182   0   0   1]\n",
      " [ 17 159 185 173 164 157 147 133 136 144 148 155 170 158 188 170   0   0   0   0   1   3   0 146 164   0   0   0]\n",
      " [  0   9 109 165 182 185 178 167 158 153 152 154 148 168 255   4   0   3   0   0   0   3   0 154 134   0   4   0]\n",
      " [  0   0   0   3  74 133 178 207 201 199 197 186 185 244  75   0   8   0   0   0   0   0   0 191 128   0   5   0]\n",
      " [  1   2   0   0   0   0   0  30  62 109 149 166 141  37   0   0   0   0   0   0   1   0   0 134  86   0   4   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c7a6c42b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de2xU9/nn8c+ML2MD9hgDvgVDDAkhDZdsSXBYUkqKBbhSFhJU5bYSRClsUhOF0DSRq1zbSm7Jb9MoESXSqoVmFXJbBVCiiv4SEozSAF0ICNEmXvC6BQI2gQRfsT32fPcPNu7PYMDfk7Ef27xf0pHsmfP4PD5zZj5zPDOPQ845JwAA+lnYugEAwJWJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJZOsGzhePx3X8+HFlZGQoFApZtwMA8OScU2NjowoKChQOX/w8Z8AF0PHjx1VYWGjdBgDgWzp69KjGjh170esHXABlZGRIkm7VD5WsFONuAAC+OhTTx/pT1+P5xfRZAK1du1bPP/+8amtrNX36dL388suaOXPmZeu++bNbslKUHCKAAGDQ+f8TRi/3MkqfvAnhzTff1OrVq/XMM8/o008/1fTp07VgwQKdPHmyLzYHABiE+iSAXnjhBS1fvlz333+/vvOd7+iVV17RsGHD9Ic//KEvNgcAGIQSHkDt7e3au3evSkpK/rWRcFglJSXauXPnBeu3tbWpoaGh2wIAGPoSHkCnTp1SZ2encnNzu12em5ur2traC9avqKhQNBrtWngHHABcGcw/iFpeXq76+vqu5ejRo9YtAQD6QcLfBTd69GglJSWprq6u2+V1dXXKy8u7YP1IJKJIJJLoNgAAA1zCz4BSU1M1Y8YMbdu2reuyeDyubdu2adasWYneHABgkOqTzwGtXr1aS5cu1U033aSZM2fqxRdfVHNzs+6///6+2BwAYBDqkwC666679OWXX+rpp59WbW2tbrzxRm3duvWCNyYAAK5cIeecs27iP2poaFA0GtVcLWISAgAMQh0upu3aovr6emVmZl50PfN3wQEArkwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARLJ1A7jChEL+JUlJ3jWuo8O7RpKSJ1ztXfP5w3neNeGY/35I/dq/JvMfce8aSYq+s8+7xrW1+W8oyPGQnOJd42Lt3jXoe5wBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMEwUgx4Lu76bVvVy/K9a5Lym71rOtr873qxwk7vmvD3G71rJKlq3lTvmkk/3uO/Ied/2/brYNFwgEG4t0zxrjn0Y/8Bq1mjmrxrJCln0ef+Rb77wcWlXszB5QwIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACYaRon8FGD4ZSg4wEDLuP7hTkkIdIe+aIINF5b8ZpaR2eNecbhjuvyFJd/6nT71r/haJeNe4tjbvmq/un+Vf84NW7xpJysryHzQ7Pnrcu2ZCe7p3Tc3n/oNzJSknSJHv/cn1bn3OgAAAJgggAICJhAfQs88+q1Ao1G2ZPHlyojcDABjk+uQ1oBtuuEEffPDBvzaSzEtNAIDu+iQZkpOTlZeX1xc/GgAwRPTJa0CHDh1SQUGBJkyYoPvuu09Hjhy56LptbW1qaGjotgAAhr6EB1BxcbE2bNigrVu3at26daqpqdH3vvc9NTb2/L/pKyoqFI1Gu5bCwsJEtwQAGIASHkClpaX60Y9+pGnTpmnBggX605/+pDNnzuitt97qcf3y8nLV19d3LUePHk10SwCAAajP3x2QlZWlSZMm6fDhwz1eH4lEFAnwATYAwODW558DampqUnV1tfLzg31qFwAwNCU8gB577DFVVlbqH//4hz755BPdcccdSkpK0j333JPoTQEABrGE/wnu2LFjuueee3T69GmNGTNGt956q3bt2qUxY8YkelMAgEEs4QH0xhtvJPpH4grnOoMNFg2iY4T/sFQXDzBZtNO/Zkye/2DM46ej3jWSNDKlxbsmnJ7rXVP91He9azb/1//uXfPU0f/iXSNJHXH/QbiNsTTvmq9b/IeRukjcu2agYRYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE33+D+mAbkIBBne6/hu62DGyw78o5v88Lvlr/7vesfSR3jWdDSneNZLU0pnqX1TgP4x04ux/etc8+n9/5F3jXIDjLqBYp/8A0/TUmHdNwbXHvGskqSPZ/9hzHQHuF73AGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwATTsNG/nPOvCftPF5br9K+RpFiAqcnp/tvqyPafLpwS9p8KHh7Z6l0jSSNTmr1rGq73n9Y9PN7iXZOR6v87xQNOwz7RnOld0xbzf1htafWfPn7vuP/tXSNJm2eXeNeEK/cF2tZlf26f/FQAAC6DAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACYaRon+FAgyFjAcYLBpkO5LCrf7PyULRmP920v1r0tP8azo6++85ZmxYgH0X8h9OW9+e7l1zqmm4d01QkRT/QbNNAW6nP1TP8q6RpK/u83/Yn1QZaFOXxRkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwwjRf8KBXjO4/yHkSaPvcp/O5Lc6Hb/mg7/waehAPuhM+5fEw77D/uUpM+b8r1rWvL990Om8/+dhif730Zfhf0HmEpSOMBM2yC3U3q6/+/U3hHs4Xv2lEPeNadSUr3WD7mQ1IvZuZwBAQBMEEAAABPeAbRjxw7dfvvtKigoUCgU0ubNm7td75zT008/rfz8fKWnp6ukpESHDvmf8gEAhjbvAGpubtb06dO1du3aHq9fs2aNXnrpJb3yyivavXu3hg8frgULFqi1tfVbNwsAGDq8X8UqLS1VaWlpj9c55/Tiiy/qySef1KJFiyRJr776qnJzc7V582bdfffd365bAMCQkdDXgGpqalRbW6uSkpKuy6LRqIqLi7Vz584ea9ra2tTQ0NBtAQAMfQkNoNraWklSbm5ut8tzc3O7rjtfRUWFotFo11JYWJjIlgAAA5T5u+DKy8tVX1/ftRw9etS6JQBAP0hoAOXl5UmS6urqul1eV1fXdd35IpGIMjMzuy0AgKEvoQFUVFSkvLw8bdu2reuyhoYG7d69W7NmzUrkpgAAg5z3u+Campp0+PDhru9ramq0f/9+ZWdna9y4cVq1apV+9atf6dprr1VRUZGeeuopFRQUaPHixQltHAAwuHkH0J49e3Tbbbd1fb969WpJ0tKlS7VhwwY9/vjjam5u1ooVK3TmzBndeuut2rp1q9LS0hLXNQBg0As554JNK+wjDQ0NikajmqtFSg6lWLeDBAt5DjWUJBfzH9TYOfe73jWSVPeI/wemW5oi3jVpw/x/p2GRXkx3PM/wVP/tSFJ2WrN3TTzAYNHcdP+PXXzRkuVdc7Yj2GNJQ6v/E+ekcNy7pqnV/xgK+si98OrPvGsOPDLNa/2Ojlbt2Pkr1dfXX/J1ffN3wQEArkwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPe/44BAYVC/jVBxt2GkwJsx396ryQp5P/8Jchk6yBqFvlP3ZakMRH/6cydnf77IZLS4V2TmeY/qXtUgKnWklTflu5dEwr5H6/1Mf/t1DVleNd0BLiNJOlsm/8U7ZSUTu+ajHT/27ajM8B9XVJDh/8+j6f6bSvey8chzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYBhpf+mvwaJx/0GIQYWS/AesBpl7Gpt/k3dNdOLX/huSdOpr/0GXGSPOBtqWr7YO/7trkKGiQZ1p9d9Wp/N/DjxqmP+A1ZZYsOG0GWlt3jUpSf73wZSwf41zAQYcSypIO+Nd849OvztuuJfrcwYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABMNI+0sowODAfhosGopEAtW5Nv9BjaEU/6GQ/yz1P0zjJzK9ayQpJbPdu6Yj7v88LjnsP5U1wDhbtXUGu4vHAwy6HJ7qv+8yUlq9a1o7U7xrcoY1etdIwfZDOOR/SwX5nYL6OjbMuybpk795re9crFfrcQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxMAdRhoK+Q3wdEFGNfajfuovyGDRIENFg/rikZu8a+JZ/v2FzwQb7hhL8a/r7PB/Hpea1uFdE0nxrxmW0ruhkOcLBxh9Gpf/4M4RKf63bZDBnV80Rb1rJKkt5v8QmZnm/zvFAgy0be8I9vBd8+9F3jVjY594rc8wUgDAgEYAAQBMeAfQjh07dPvtt6ugoEChUEibN2/udv2yZcsUCoW6LQsXLkxYwwCAocE7gJqbmzV9+nStXbv2oussXLhQJ06c6Fpef/31b9UkAGDo8X4Vq7S0VKWlpZdcJxKJKC8vL3BTAIChr09eA9q+fbtycnJ03XXX6aGHHtLp06cvum5bW5saGhq6LQCAoS/hAbRw4UK9+uqr2rZtm37zm9+osrJSpaWl6uzs7HH9iooKRaPRrqWwsDDRLQEABqCEfw7o7rvv7vp66tSpmjZtmiZOnKjt27dr3rx5F6xfXl6u1atXd33f0NBACAHAFaDP34Y9YcIEjR49WocPH+7x+kgkoszMzG4LAGDo6/MAOnbsmE6fPq38/Py+3hQAYBDx/hNcU1NTt7OZmpoa7d+/X9nZ2crOztZzzz2nJUuWKC8vT9XV1Xr88cd1zTXXaMGCBQltHAAwuHkH0J49e3Tbbbd1ff/N6zdLly7VunXrdODAAf3xj3/UmTNnVFBQoPnz5+uXv/ylIgFmlAEAhi7vAJo7d67cJQZr/vnPf/5WDXVxTvIZiBhO8t5EKOw/PDEoF/cf7hhK8v+d+nOw6Mmy/+xd0zyu53dDXkrkiP+Tl/ZR/tuRpKSIf11qxH/gZ6zd//0/oZD/MZQSDrYfwgG2FXf+96cvmrO8a+aM6fn15EsZHznlXSNJf2u5yrvmRKv/4NO/fen/ucmOAANMJWnce19518QDbenymAUHADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCR8H/JnSihlFSFQim9Xt/F2r234fpqxGuCuLj/JOPwsGHeNafunu5dI0n11/n3l9zs/5ynPdt/Oy4t2BToIJOt01L9a1KS/fvLTPWfdB5kQrUkDUv2vz990eQ/BXrlhO3eNc/svd27ZtIjX3jXSFLnl1961/yfP1zjXXPN+Drvmi++9t/fkhQ/8PdAdX2BMyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmBuwwUhdrlwu5Pt1G0ncmBaqLjRnuXdOSk+pd03B1kndN26gA+yzgbk5q9X/+EhsZYEhoqv/U2FBSsEmzLsDwzqbmNO+aaMZZ75oO57+/U0LBhrKeaM70rrn/6p3eNb/+H3d510z8t0+8a4LthWBSv+j9EOVv3HjjMe+amn1XedcMNJwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMDFgh5GGM0YoHOr9AM/DT07x3kZHVod3jSQlf+2/2zpH+A/HTG7ynxIainmXqCMj2DRSlxSgLkBNUsR/lGQ4Kdj4yXDY/3aKRv0Hi44e1uxdEw8wKPXr1nTvGkl6ZMKH3jUvPe0/WLTgTf/BokGEIpFAda6tLcGd9Gxkcot3zdiP+nHEasj32Av1asgxZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMDNhhpM3fv07JKWm9Xr9jlP8UzpQvU7xrJCkUZAZgS/9kvQvyK/nP3zy3reH+heE0/wGwaent3jWRlABTWSUNT/Wvy07zHyR5tsP/hvqyebh3zfM3/C/vGkn6+bMrvGuy3twZaFu+QskBHrY6+29wZyjuPzT2dMz/tk3/6G/eNVKwu3soKclvfReXenFX5wwIAGCCAAIAmPAKoIqKCt18883KyMhQTk6OFi9erKqqqm7rtLa2qqysTKNGjdKIESO0ZMkS1dXVJbRpAMDg5xVAlZWVKisr065du/T+++8rFotp/vz5am7+1z/XevTRR/Xuu+/q7bffVmVlpY4fP64777wz4Y0DAAY3r1fztm7d2u37DRs2KCcnR3v37tWcOXNUX1+v3//+99q4caN+8IMfSJLWr1+v66+/Xrt27dItt9ySuM4BAIPat3oNqL6+XpKUnZ0tSdq7d69isZhKSkq61pk8ebLGjRunnTt7fodMW1ubGhoaui0AgKEvcADF43GtWrVKs2fP1pQpUyRJtbW1Sk1NVVZWVrd1c3NzVVtb2+PPqaioUDQa7VoKCwuDtgQAGEQCB1BZWZkOHjyoN95441s1UF5ervr6+q7l6NGj3+rnAQAGh0AfRF25cqXee+897dixQ2PHju26PC8vT+3t7Tpz5ky3s6C6ujrl5eX1+LMikYgikUiQNgAAg5jXGZBzTitXrtSmTZv04YcfqqioqNv1M2bMUEpKirZt29Z1WVVVlY4cOaJZs2YlpmMAwJDgdQZUVlamjRs3asuWLcrIyOh6XScajSo9PV3RaFQPPPCAVq9erezsbGVmZurhhx/WrFmzeAccAKAbrwBat26dJGnu3LndLl+/fr2WLVsmSfrtb3+rcDisJUuWqK2tTQsWLNDvfve7hDQLABg6vALIOXfZddLS0rR27VqtXbs2cFOSlHw2ruRY78fmjR93ynsbR1KyvWskybX6DeaTpPBZ/xqXfPn9fUFNWoChix0B34uS7D/WMClATWqy/wDTjk7//S1J7Z3+/bXH/bdV25jhXfP49f/uXVP+S/+hopI08n/2z2BRhfwHd7oO/+OhP3WM8D+GqhpzvWviLSe8a4JynsNcnevd+syCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYCPQfUftD+sEvlBxO7fX6NQ1jvLdxY1Gwf/99ssV/knFjq/9/fW1r97952s+meNcowHRvSXLOvy7m/Kcfn4n5byc5NdjE5PTUmHdNzalR3jXTC77wrnm5+jbvmpEb+mmqdVC9mLB/gQATtENJAY/xAJO346P8j6GjZ7Iuv9J58tR/07C9b6ders8ZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMDdhhpR91JKdT7wZrj72/x3sbnq6Z610hS5KavvGsKs85416SG/QchNsbSvGu+akn3rpGklgADVjsCDBYNMK5SCjD0VJJOnsr0rhmV3eRd80bRh941C8fP9K4JtO8khZL9HxqCDO4MJMgA036UHAlwv/3C/7jL8644J5TS+yHP33Cx9oBbuzTOgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYsMNIfcUbG71rCn/5SaBtBRnUeOqum7xrTs7yH7o48frj3jV3jD/gXSNJ9R3+Q0xjzn8YaUfcv6a2NcO7RpLiAYaYvnT1Ju+aWx5/zLsmGtvlXRMePty7RpLizc2B6gaqfhuUKumWq2u8a/5S+50+6OQiwsEG9fYFzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYGLjDSEOhc0uv1w+QpfFO/xoFG2wYfc1/kGT0Ne+SQD65fmqguqZJI71rTk3zP+TaJp31rolGW7xrJOnrukzvmh8/8t+8a6L7/I+HIIbaUFFJfo8L33D+g32D+vjT671rRn7ejwNC4/23Ly6HMyAAgAkCCABgwiuAKioqdPPNNysjI0M5OTlavHixqqqquq0zd+5chUKhbsuDDz6Y0KYBAIOfVwBVVlaqrKxMu3bt0vvvv69YLKb58+er+by/My9fvlwnTpzoWtasWZPQpgEAg5/XK8Jbt27t9v2GDRuUk5OjvXv3as6cOV2XDxs2THl5eYnpEAAwJH2r14Dq6+slSdnZ2d0uf+211zR69GhNmTJF5eXlamm5+DuS2tra1NDQ0G0BAAx9gd+GHY/HtWrVKs2ePVtTpkzpuvzee+/V+PHjVVBQoAMHDuiJJ55QVVWV3nnnnR5/TkVFhZ577rmgbQAABqnAAVRWVqaDBw/q448/7nb5ihUrur6eOnWq8vPzNW/ePFVXV2vixIkX/Jzy8nKtXr266/uGhgYVFhYGbQsAMEgECqCVK1fqvffe044dOzR27NhLrltcXCxJOnz4cI8BFIlEFIlEgrQBABjEvALIOaeHH35YmzZt0vbt21VUVHTZmv3790uS8vPzg3UIABiSvAKorKxMGzdu1JYtW5SRkaHa2lpJUjQaVXp6uqqrq7Vx40b98Ic/1KhRo3TgwAE9+uijmjNnjqZNm9YnvwAAYHDyCqB169ZJOvdh0/9o/fr1WrZsmVJTU/XBBx/oxRdfVHNzswoLC7VkyRI9+eSTCWsYADA0eP8J7lIKCwtVWVn5rRoCAFwZBu40bOckeUxtdcEmW0Pq/OxQoLr0z/xrCrcE2lS/GROgZuDMFr5C9ONk6yCuLdtt3cIluVi7dQtdGEYKADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARLJ1A+dzzkmSOhSTnHEzAABvHYpJ+tfj+cUMuABqbGyUJH2sPxl3AgD4NhobGxWNRi96fchdLqL6WTwe1/Hjx5WRkaFQKNTtuoaGBhUWFuro0aPKzMw06tAe++Ec9sM57Idz2A/nDIT94JxTY2OjCgoKFA5f/JWeAXcGFA6HNXbs2Euuk5mZeUUfYN9gP5zDfjiH/XAO++Ec6/1wqTOfb/AmBACACQIIAGAi6dlnn33WugkfSUlJmjt3rpKTB9xfD/sV++Ec9sM57Idz2A/nDJb9MODehAAAuDLwJzgAgAkCCABgggACAJgggAAAJgZNAK1du1ZXX3210tLSVFxcrL/+9a/WLfW7Z599VqFQqNsyefJk67b63I4dO3T77beroKBAoVBImzdv7na9c05PP/208vPzlZ6erpKSEh06dMio275zuf2wbNmyC46PhQsXGnXbNyoqKnTzzTcrIyNDOTk5Wrx4saqqqrqt09raqrKyMo0aNUojRozQkiVLVFdXZ9Rx3+jNfpg7d+4Fx8ODDz5o1HHPBkUAvfnmm1q9erWeeeYZffrpp5o+fboWLFigkydPWrfW72644QadOHGia/n444+tW+pzzc3Nmj59utauXdvj9WvWrNFLL72kV155Rbt379bw4cO1YMECtba29nOnfety+0GSFi5c2O34eP311/uxw75XWVmpsrIy7dq1S++//75isZjmz5+v5ubmrnUeffRRvfvuu3r77bdVWVmp48eP68477zTsOvF6sx8kafny5d2OhzVr1hh1fBFuEJg5c6YrKyvr+r6zs9MVFBS4iooKw6763zPPPOOmT59u3YYpSW7Tpk1d38fjcZeXl+eef/75rsvOnDnjIpGIe/311y1a7Bfn7wfnnFu6dKlbtGiRUUc2Tp486SS5yspK59y52z4lJcW9/fbbXet89tlnTpLbuXOnVZt97vz94Jxz3//+990jjzxi2NXlDfgzoPb2du3du1clJSVdl4XDYZWUlGjnzp2Gndk4dOiQCgoKNGHCBN133306cuSIdUumampqVFtb2+34iEajKi4uviKPj+3btysnJ0fXXXedHnroIZ0+fdq6pT5VX18vScrOzpYk7d27V7FYrNvxMHnyZI0bN25IHw/n74dvvPbaaxo9erSmTJmi8vJytbS0WLR3UQP7Y7KSTp06pc7OTuXm5na7PDc3V59//rlRVzaKi4u1YcMGXXfddTpx4oSee+45fe9739PBgweVkZFh3Z6J2tpaSerx+PjmuivFwoULdeedd6qoqEjV1dX6+c9/rtLSUu3cuVNJSUnW7SVcPB7XqlWrNHv2bE2ZMkXSueMhNTVVWVlZ3dYdysdDT/tBku69916NHz9eBQUFOnDggJ544glVVVXpnXfeMey2uwEfQPiX0tLSrq+nTZum4uJijR8/Xm+99ZYeeOABw84wENx9991dX0+dOlXTpk3TxIkTtX37ds2bN8+ws75RVlamgwcPXhGvg17KxfbDihUrur6eOnWq8vPzNW/ePFVXV2vixIn93WaPBvyf4EaPHq2kpKQL3sVSV1envLw8o64GhqysLE2aNEmHDx+2bsXMN8cAx8eFJkyYoNGjRw/J42PlypV677339NFHH3X79y15eXlqb2/XmTNnuq0/VI+Hi+2HnhQXF0vSgKeZBasAAAKFSURBVDoeBnwApaamasaMGdq2bVvXZfF4XNu2bdOsWbMMO7PX1NSk6upq5efnW7dipqioSHl5ed2Oj4aGBu3evfuKPz6OHTum06dPD6njwzmnlStXatOmTfrwww9VVFTU7foZM2YoJSWl2/FQVVWlI0eODKnj4XL7oSf79++XpIF1PFi/C6I33njjDReJRNyGDRvc3//+d7dixQqXlZXlamtrrVvrVz/96U/d9u3bXU1NjfvLX/7iSkpK3OjRo93JkyetW+tTjY2Nbt++fW7fvn1OknvhhRfcvn373D//+U/nnHO//vWvXVZWltuyZYs7cOCAW7RokSsqKnJnz5417jyxLrUfGhsb3WOPPeZ27tzpampq3AcffOC++93vumuvvda1trZat54wDz30kItGo2779u3uxIkTXUtLS0vXOg8++KAbN26c+/DDD92ePXvcrFmz3KxZswy7TrzL7YfDhw+7X/ziF27Pnj2upqbGbdmyxU2YMMHNmTPHuPPuBkUAOefcyy+/7MaNG+dSU1PdzJkz3a5du6xb6nd33XWXy8/Pd6mpqe6qq65yd911lzt8+LB1W33uo48+cpIuWJYuXeqcO/dW7Keeesrl5ua6SCTi5s2b56qqqmyb7gOX2g8tLS1u/vz5bsyYMS4lJcWNHz/eLV++fMg9Sevp95fk1q9f37XO2bNn3U9+8hM3cuRIN2zYMHfHHXe4EydO2DXdBy63H44cOeLmzJnjsrOzXSQScddcc4372c9+5urr620bPw//jgEAYGLAvwYEABiaCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmPh/q/emUu5oSRAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize your data\n",
    "index = random.choice(range(59999)) # You can put between 0 to 59999 here\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c17a9b8f-6163-4346-bf30-0a8584ed0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and test images\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e57064ea-64e2-4381-8ebf-c9a9be7b2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eecd712-901f-4c6f-b9db-0e6dbf41affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n",
      "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 0.9999999999999999\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "# Declare sampleinputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "#Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac453f1b-3918-46d6-aee7-890752fbb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "233430de-fb76-4683-b80b-1041fbaf6877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 818us/step - loss: 0.4963 - accuracy: 0.8243\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3747 - accuracy: 0.8654\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3353 - accuracy: 0.8775\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.3121 - accuracy: 0.8841\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.2902 - accuracy: 0.8928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c7a3fd3d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "844ef22d-6497-43e8-82b6-307ed5c694c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 826us/step - loss: 0.3467 - accuracy: 0.8743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34666895866394043, 0.8743000030517578]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c949cc75-52f6-4cff-8282-746fe8a40907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.9562630e-05 3.8281449e-08 3.7804421e-05 4.9050794e-07 3.6895010e-06 9.8551977e-03 9.4535171e-05 5.0445117e-02 5.4619442e-05 9.3944889e-01]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c39496e-8650-4e0f-8ad3-e7c69645c228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.4724\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3573\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 743us/step - loss: 0.3214\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 558us/step - loss: 0.2991\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 624us/step - loss: 0.2788\n",
      "313/313 [==============================] - 0s 747us/step - loss: 0.3567\n",
      "0.3566604554653168\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Excercise 2 512-neurons\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 5)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2841f5e0-e3d5-4127-bfe7-c292f5090cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 968us/step - loss: 0.4754\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 945us/step - loss: 0.3579\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3219\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2967\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2792\n",
      "313/313 [==============================] - 0s 542us/step - loss: 0.3323\n",
      "0.33231157064437866\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Excercise 3 1024-neurons\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 5)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ac5d5a0-7e72-4cd5-bfe7-bc2948f94405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.4686\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3554\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 615us/step - loss: 0.3207\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2969\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2748\n",
      "313/313 [==============================] - 0s 568us/step - loss: 0.3484\n",
      "0.34836310148239136\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Excerise 5 Add layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 5)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6181c440-d115-4664-973c-b8410531ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 2s 788us/step - loss: 0.4670\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3570\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3183\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2939\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2818\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 2s 883us/step - loss: 0.2651\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.2507\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2417\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 2s 924us/step - loss: 0.2307\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2195\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2133\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2044\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1988\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1895\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.1829\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3677\n",
      "0.3677322268486023\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 15)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4a87c32-efc4-4c78-be56-339d3c8085a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4679\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3569\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3201\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 891us/step - loss: 0.2961\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.2782\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 2s 896us/step - loss: 0.2636\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2531\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2413\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2313\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2209\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 0.2126\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 2s 980us/step - loss: 0.2024\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1990\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1893\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1820\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1797\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1684\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1654\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1619\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.1551\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 2s 951us/step - loss: 0.1505\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1484\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1424\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1410\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.1378\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 2s 943us/step - loss: 0.1291\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1272\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1228\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1235\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.1186\n",
      "313/313 [==============================] - 0s 862us/step - loss: 0.4615\n",
      "0.461531400680542\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 30)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d7c5a22-f87a-436c-97c3-c449141668ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 4.1698\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.5409\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5096\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 946us/step - loss: 0.4997\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 1s 633us/step - loss: 0.4880\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.4786\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 2s 972us/step - loss: 0.4540\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.4458\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 1s 581us/step - loss: 0.4526\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4485\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 2s 843us/step - loss: 0.4497\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4474\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 2s 832us/step - loss: 0.4387\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.4384\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.4313\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4358\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 2s 851us/step - loss: 0.4332\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.4280\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.4209\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4239\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.4243\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 1s 485us/step - loss: 0.4221\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 1s 504us/step - loss: 0.4164\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 2s 884us/step - loss: 0.4143\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4214\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4182\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4177\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4175\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 2s 934us/step - loss: 0.4122\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 2s 813us/step - loss: 0.4056\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.6034\n",
      "0.6033788919448853\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels),(test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "#training_images = training_images/255.0\n",
    "#test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 30)\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6ecef2b-95a4-4e24-9e43-94d3a4ead26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1857/1875 [============================>.] - ETA: 0s - loss: 0.4752 - accuracy: 0.8299\n",
      "Reached 60% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 1s 571us/step - loss: 0.4747 - accuracy: 0.8301\n",
      "313/313 [==============================] - 0s 684us/step - loss: 0.4531 - accuracy: 0.8334\n",
      "[0.4530821740627289, 0.8334000110626221]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8 Callback\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >=0.6):\n",
    "            print('\\nReached 60% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels),(test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs= 5, callbacks=[callbacks])\n",
    "\n",
    "print(model.evaluate(test_images, test_labels))\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dc351-ab0c-417a-849f-622fee581e6e",
   "metadata": {},
   "source": [
    "# references\n",
    "\n",
    "[Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "[Sequential](https://keras.io/api/models/sequential/)\n",
    "\n",
    "[Flatten](https://keras.io/api/layers/reshaping_layers/flatten/)\n",
    "\n",
    "[Dense](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "[ReLU](https://keras.io/api/layers/activations/#relu-function)\n",
    "\n",
    "[Softmax](https://keras.io/api/layers/activations/#softmax-function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
