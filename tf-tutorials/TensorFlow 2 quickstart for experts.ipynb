{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97fb240-d349-41b5-9c2d-ddf28759e91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a26d978-7996-418e-bd7f-989015a77507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (60000, 28, 28)\n",
      "x_test (10000, 28, 28)\n",
      "x_train (60000, 28, 28, 1)\n",
      "x_test (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "print('x_train',x_train.shape)\n",
    "print('x_test',x_test.shape)\n",
    "\n",
    "# Add channels dimension\n",
    "x_train = x_train[...,tf.newaxis].astype('float32')\n",
    "x_test = x_test[...,tf.newaxis].astype('float32')\n",
    "print('x_train',x_train.shape)\n",
    "print('x_test',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0117ac0c-a255-4ece-90e2-56fce75c69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 05:53:56.739805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.739956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.782008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.782171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.782292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.782553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.782654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1932] Ignoring visible gpu device (device: 1, name: NVIDIA GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0) with core count: 5. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2024-02-20 05:53:56.783399: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 05:53:56.784590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.784723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:56.784838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:57.240576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:57.240712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:57.240806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-20 05:53:57.240905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10227 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:05:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Use tf.data to batch and shuflfle the dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935d9bd-9eb7-4bae-953d-b3662bdf38b3",
   "metadata": {},
   "source": [
    "# Build model with Keras model subclassing API\n",
    "[model subclassing API](https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37fa52e0-88ac-4de6-b269-0879428f6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "    def call (self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fceccd5-4aa2-4754-a991-994bb4851295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimizer and loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3046f7cb-0a4a-47c6-a2e2-2cb58e29ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select metrics to measure the loss and the accuracy of the model\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833c197-1f3c-4e65-a0af-c0b3f67bd91c",
   "metadata": {},
   "source": [
    "Use [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b7deb3-38b5-4ace-addf-3e66c3b3ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f53d5b45-8a6f-417d-a825-6a41239fda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0902b06c-b8b0-4bd2-87dd-135fac50cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.00449703074991703, Accuracy: 99.85166931152344, Test Loss: 0.074483722448349, Test Accuracy: 98.48999786376953\n",
      "Epoch 2, Loss: 0.004290905315428972, Accuracy: 99.8499984741211, Test Loss: 0.08137967437505722, Test Accuracy: 98.50999450683594\n",
      "Epoch 3, Loss: 0.004437723662704229, Accuracy: 99.83666229248047, Test Loss: 0.07179128378629684, Test Accuracy: 98.55999755859375\n",
      "Epoch 4, Loss: 0.003813032526522875, Accuracy: 99.89167022705078, Test Loss: 0.07635362446308136, Test Accuracy: 98.44999694824219\n",
      "Epoch 5, Loss: 0.003679735818877816, Accuracy: 99.875, Test Loss: 0.07912774384021759, Test Accuracy: 98.56999969482422\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    # Train model with batch\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images,labels)\n",
    "    # Test model\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b60ae-b507-42ec-ab36-391c5a79870f",
   "metadata": {},
   "source": [
    "# Build model with Functional API\n",
    "[The Functional API](https://www.tensorflow.org/guide/keras/functional_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfe5e7-0df1-43de-ae61-32e95264398f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4ee55-7cb3-44ad-8830-3fdfb349f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58785c5-269b-4d0e-91a7-2cd3bb0ac299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bddf9-39d9-4446-ad12-fc784e20310e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
